#!/usr/bin/python3
#
# Copyright (c) 2020 Sorcero, Inc.
#
# This file is part of Sorcero's Language Intelligence platform
# (see https://www.sorcero.com).
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Lesser General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public License
# along with this program. If not, see <http://www.gnu.org/licenses/>.
#

import json
import argparse
import tempfile
import pathlib

from ingestum import engine
from ingestum import manifests
from ingestum import pipelines


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("pipeline")
    parser.add_argument("--path", default=None)
    parser.add_argument("--target", default=None)
    parser.add_argument("--search", default=None)
    parser.add_argument("--terms", default=None)
    parser.add_argument("--hours", default=None)
    parser.add_argument("--articles", default=None)
    parser.add_argument("--first-page", default=None)
    parser.add_argument("--last-page", default=None)
    parser.add_argument("--workspace", default=None)
    parser.add_argument("--reddit-search", default=None)
    parser.add_argument("--subreddit", default="all")
    parser.add_argument("--query", default=None)
    parser.add_argument("--databases", default=None)

    args = parser.parse_args()

    source_class = None
    sources_args = {}
    workspace = args.workspace
    pipeline = pipelines.Base.parse_file(args.pipeline)

    if args.path:
        source_class = pipeline.pipes[0].sources[0].get_source_class()
        sources_args["location"] = manifests.sources.locations.Local(path=args.path)
    if args.target:
        source_class = manifests.sources.HTML
        sources_args["target"] = args.target
    if args.first_page and args.last_page:
        source_class = manifests.sources.PDF
        sources_args["first_page"] = args.first_page
        sources_args["last_page"] = args.last_page
    if args.search:
        source_class = manifests.sources.Twitter
        sources_args["search"] = args.search
    if args.terms and args.hours and args.articles:
        source_class = manifests.sources.PubMed
        sources_args["terms"] = [args.terms]
        sources_args["hours"] = args.hours
        sources_args["articles"] = args.articles
    if args.reddit_search:
        source_class = manifests.sources.Reddit
        sources_args["search"] = args.reddit_search
        sources_args["subreddit"] = args.subreddit
    if args.query and args.databases and args.articles:
        source_class = manifests.sources.ProQuest
        sources_args["query"] = args.query
        sources_args["databases"] = [args.databases]
        sources_args["articles"] = args.articles

    if source_class is None:
        raise Exception("No source was identified")

    tmp_destination = tempfile.TemporaryDirectory()
    tmp_artifacts = tempfile.TemporaryDirectory()
    tmp_workspace = None

    if workspace is not None:
        pathlib.Path(workspace).mkdir(parents=True, exist_ok=True)
    else:
        tmp_workspace = tempfile.TemporaryDirectory()
        workspace = tmp_workspace.name

    source = source_class(
        id="id",
        pipeline=pipeline.name,
        destination=manifests.sources.destinations.Local(directory=tmp_destination.name),
        **sources_args,
    )

    results, _ = engine.run(
        manifest=manifests.Base(sources=[source]),
        pipelines=[pipeline],
        pipelines_dir=None,
        artifacts_dir=tmp_artifacts.name,
        workspace_dir=workspace,
    )

    tmp_destination.cleanup()
    tmp_artifacts.cleanup()
    if tmp_workspace is not None:
        tmp_workspace.cleanup()

    print(json.dumps(results[0].dict(), indent=4, sort_keys=True))


if __name__ == "__main__":
    main()
